# WeaveHelp Chatbot

A modern AI-powered customer support chatbot built with Next.js, TypeScript, and LlamaIndex.

## Features

- ðŸ¤– AI-powered responses using LlamaIndex and LlamaCloud
- ðŸŒ™ Dark/Light theme toggle with session persistence
- ðŸ’¬ Real-time chat interface
- ðŸ“± Responsive design
- âš¡ Fast and modern UI

## Setup

### 1. Install Dependencies

```bash
npm install llamaindex
```

### 2. Environment Variables

Create a `.env.local` file in the root directory and add your LlamaCloud API key:

```env
LLAMA_CLOUD_API_KEY=your_llama_cloud_api_key_here
```

### 3. LlamaCloud Configuration

The chatbot is configured to use:
- **Index Name**: Alvin
- **Project Name**: Default
- **Organization ID**: e01ec0f2-99dd-4049-85b4-430fc8d8ac92
- **Similarity Top K**: 5

Make sure your LlamaCloud account has the correct index and project set up.

### 4. Run the Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to view the chatbot.

## Architecture

- **Frontend**: Next.js 15 with TypeScript and Tailwind CSS
- **AI Backend**: LlamaIndex with LlamaCloudIndex
- **API Routes**: Next.js API routes for handling chat requests
- **State Management**: React hooks with session storage for theme persistence

## File Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/chat/route.ts    # API endpoint for chat
â”‚   â”œâ”€â”€ page.tsx             # Main chatbot component
â”‚   â””â”€â”€ layout.tsx           # App layout
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ llama-service.ts     # LlamaIndex service
â”œâ”€â”€ components/
â”‚   â””â”€â”€ ui/                  # UI components
â””â”€â”€ styles/
    â””â”€â”€ globals.css          # Global styles
```

## Usage

1. Type your message in the input field
2. Press Enter or click the send button
3. The AI will respond using your LlamaCloud index
4. Toggle between dark and light themes using the switch

## Error Handling

The chatbot includes comprehensive error handling:
- API failures are gracefully handled
- User-friendly error messages
- Fallback responses when services are unavailable

## Customization

You can customize the LlamaIndex configuration in `lib/llama-service.ts`:
- Change the index name, project name, or organization ID
- Adjust the similarity top K value
- Modify the chat engine settings # weavehelp-ai
